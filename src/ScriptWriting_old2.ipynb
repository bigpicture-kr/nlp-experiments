{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a19b76-30ec-47e6-8a6f-245ab4ad5d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 23:56:39.667862: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-29 23:56:46.137639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:46.146161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:46.146716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:46.150566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-29 23:56:46.155461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:46.156022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:46.156543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:50.956912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:50.957683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:50.958398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-29 23:56:50.959098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13263 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gluonnlp as nlp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gluonnlp.data import SentencepieceTokenizer # Use the tokenizer that SKT used to train KoGPT2\n",
    "from transformers import TFGPT2LMHeadModel\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b31ab9-a3c0-47ab-b76b-0c0b13ac63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Model(tf.keras.Model):\n",
    "    def __init__(self, dir_path):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.gpt2(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba81301-2e0d-49ee-9b8d-166f33562a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./gpt_ckpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_PATH = './gpt_ckpt'\n",
    "gpt_model = GPT2Model(BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b3fca5-7336-43a0-8811-def36f9bfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "MAX_LEN = 30\n",
    "TOKENIZER_PATH = f'{BASE_MODEL_PATH}/gpt2_kor_tokenizer.spiece'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dfa863-7983-4cfb-af5f-a4ac37d18d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(\n",
    "    TOKENIZER_PATH,\n",
    "    mask_token=None,\n",
    "    sep_token=None,\n",
    "    cls_token=None,\n",
    "    unknown_token='<unk>',\n",
    "    padding_token='<pad>',\n",
    "    bos_token='<s>',\n",
    "    eos_token='</s>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061c7e28-368f-48bb-990c-9d4cecf6a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
    "    _logits = logits.numpy()\n",
    "    top_k = min(top_k, logits.shape[-1])\n",
    "    \n",
    "    if top_k > 0:\n",
    "        indices_to_remove = logits < tf.math.top_k(logits, top_k)[0][..., -1, None]\n",
    "        _logits[indices_to_remove] = filter_value\n",
    "    \n",
    "    if top_p > 0.0:\n",
    "        sorted_logits = tf.sort(logits, direction='DESCENDING')\n",
    "        sorted_indices = tf.argsort(logits, direction='DESCENDING')\n",
    "        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n",
    "        \n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis=0)\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n",
    "        \n",
    "        _logits[indices_to_remove] = filter_value\n",
    "    return tf.constant([_logits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e886bd6-f901-43a7-8024-d636678ac063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sent(seed_word, model, max_step=100, greedy=False, top_k=0, top_p=0.):\n",
    "    sent = seed_word\n",
    "    toked = tokenizer(sent)\n",
    "    \n",
    "    for _ in range(max_step):\n",
    "        input_ids = tf.constant([vocab[vocab.bos_token],] + vocab[toked])[None, :]\n",
    "        outputs = model(input_ids)[:, -1, :]\n",
    "        \n",
    "        if greedy:\n",
    "            # Select the most probable word and convert it to text\n",
    "            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n",
    "        else:\n",
    "            # Select word randomly based on probability distribution and convert it to text\n",
    "            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n",
    "            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n",
    "        \n",
    "        # Stop when eos token generated\n",
    "        if gen == vocab.eos_token:\n",
    "            break\n",
    "        \n",
    "        sent += gen.replace('▁', ' ')\n",
    "        toked = tokenizer(sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc007793-93bf-437e-99d8-d94282f1db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘은 그녀와 함께                                                                                               '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent('오늘', gpt_model, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3285871-3e35-4b77-ac4d-ef5cadba6c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이때부터 그 그냥 고맙다'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent('이때', gpt_model, top_k=0, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2dd425c-e71e-4524-8a9b-3b99a2a83c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset/jjaltoon_scripts_raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cd4f2d-303f-4416-a067-5e1354c6ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "\n",
    "file_names = os.listdir(DATASET_PATH)\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(DATASET_PATH, file_name)\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        sents += [s[:-1] for s in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926d9bf1-5229-4850-8852-8e544e922ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd00c79-583e-45f5-a206-fba6ad969019",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for s in sents:\n",
    "    tokens = [vocab[vocab.bos_token],] + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n",
    "    input_data.append(tokens[:-1])\n",
    "    output_data.append(tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9286f4-a1c7-43af-be11-30f598393fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
    "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
    "\n",
    "input_data = np.array(input_data, dtype=np.int64)\n",
    "output_data = np.array(output_data, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dffe102b-706e-4d02-aa97-e0257c50ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3997b2c4-019b-49fa-b3d8-368b2204a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb8d564-cbee-40da-9af0-85d65c74dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    \n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "    \n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a603ecba-1cb9-4741-8302-72e8c7adc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model.compile(loss=loss_function,\n",
    "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc700bff-f6bd-4f6e-91f9-d82e07fa0a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "190/190 [==============================] - 42s 169ms/step - loss: 2.2641 - accuracy_function: 0.3516 - val_loss: 2.0868 - val_accuracy_function: 0.4489\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 31s 161ms/step - loss: 1.1540 - accuracy_function: 0.4988 - val_loss: 1.7016 - val_accuracy_function: 0.5373\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 32s 166ms/step - loss: 0.8168 - accuracy_function: 0.5654 - val_loss: 1.3940 - val_accuracy_function: 0.5885\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 32s 169ms/step - loss: 0.6342 - accuracy_function: 0.6072 - val_loss: 1.1494 - val_accuracy_function: 0.6234\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 33s 172ms/step - loss: 0.5063 - accuracy_function: 0.6376 - val_loss: 0.9292 - val_accuracy_function: 0.6501\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 32s 170ms/step - loss: 0.4132 - accuracy_function: 0.6614 - val_loss: 0.7210 - val_accuracy_function: 0.6714\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 32s 169ms/step - loss: 0.3438 - accuracy_function: 0.6809 - val_loss: 0.5823 - val_accuracy_function: 0.6893\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 32s 169ms/step - loss: 0.2931 - accuracy_function: 0.6973 - val_loss: 0.4633 - val_accuracy_function: 0.7044\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 33s 171ms/step - loss: 0.2586 - accuracy_function: 0.7110 - val_loss: 0.3879 - val_accuracy_function: 0.7172\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 32s 171ms/step - loss: 0.2303 - accuracy_function: 0.7230 - val_loss: 0.3294 - val_accuracy_function: 0.7281\n"
     ]
    }
   ],
   "source": [
    "history = gpt_model.fit(input_data, output_data,\n",
    "                        batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386cad13-838c-480d-84b2-bf7bdedbf19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data/out/tf2_gpt2_finetuned_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "DATA_OUT_PATH = './data/out'\n",
    "model_name = 'tf2_gpt2_finetuned_model'\n",
    "\n",
    "save_path = os.path.join(DATA_OUT_PATH, model_name)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "gpt_model.gpt2.save_pretrained(save_path)\n",
    "loaded_gpt_model = GPT2Model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e13add9-ca97-4a6f-98d9-95eb62306646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이때                                                                                                    '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent('이때', loaded_gpt_model, greedy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6cf55cc-8534-4830-8916-9df7f0ef45e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이때                                                                                                    '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent('이때', loaded_gpt_model, top_k=0, top_p=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4241c7b4-fc11-433c-ac1f-68c0be209d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'땅땅이                                                                                                    '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent('땅땅이', loaded_gpt_model, top_k=0, top_p=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90e50e-a9a7-4ee9-aa66-1ce758634d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
