{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff8777a-aae5-4c31-b4f0-e27b0257f977",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8808964-fd58-40d4-8f30-ff753dceb1e4",
   "metadata": {},
   "source": [
    "GPT-2 Model Experiment 2<br>\n",
    "Script writing in Korean\n",
    "- Data: [짤툰](https://www.youtube.com/c/%EC%A7%A4%ED%88%B01) script data\n",
    "- Model: [SKT AI KoGPT2](https://github.com/SKT-AI/KoGPT2) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d4e8c-ae61-47dd-bace-c6cd2ef924eb",
   "metadata": {},
   "source": [
    "Author: [Seongbum Seo](https://github.com/Seongbuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d233ee4-cccb-407f-b735-9704e72780ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5e40f-4428-4a00-9bb4-6708479e0a43",
   "metadata": {},
   "source": [
    "## Background Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1004042-ebde-4552-a82b-a65dd75bba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install transformers library\n",
    "%pip install -q git+https://github.com/huggingface/transformers.git\n",
    "# Install helper functions\n",
    "%pip install -q git+https://github.com/gmihaila/ml_things.git\n",
    "%pip install -q fastai==2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd515eb-a3e5-4306-a9c2-d1b9d24c543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'KoGPT2' already exists and is not an empty directory.\n",
      "Collecting matplotlib==3.1.3\n",
      "  Downloading matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.4.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.14.0)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.2\n",
      "    Uninstalling matplotlib-3.5.2:\n",
      "      Successfully uninstalled matplotlib-3.5.2\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "ml-things 0.0.1 requires matplotlib>=3.4.0, but you'll have matplotlib 3.1.3 which is incompatible.\u001b[0m\n",
      "Successfully installed matplotlib-3.1.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Clone base model\n",
    "!git clone https://github.com/SKT-AI/KoGPT2\n",
    "%pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523830f-e75e-4a24-8030-597c338949c8",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23aecab5-be93-42b5-9c1e-054ac4ea0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import fastai\n",
    "import re\n",
    "from typing import Optional\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast\n",
    "from fastai.text.all import *\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 10\n",
    "\n",
    "# Number of batches - depending on the max sequence length and GPU memory\n",
    "# For 512 sequence length batch of 10 works without cuda memory issues\n",
    "# For small sequence length can try batch of 32 or higher\n",
    "batch_size = 8\n",
    "\n",
    "# Pad or truncate text sequences to a specific length\n",
    "# If 'None' it will use maximum sequence of word piece tokens allowed by model\n",
    "max_length = 256\n",
    "\n",
    "# Look for GPU to use\n",
    "# Will use 'cpu' by default if no GPU found\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Name of the base model to use\n",
    "model_name_or_path = 'skt/kogpt2-base-v2'\n",
    "\n",
    "# Path of data to use for training\n",
    "data_path = './dataset/jjaltoon_scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9677d75-6a3b-42b9-a51e-521d976105d7",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6871e15-ea34-4cac-92f4-cd4530479938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptDataset(Dataset):\n",
    "    def __init__(self, path, use_tokenizer):\n",
    "        # Check if path exists\n",
    "        if not os.path.isdir(path):\n",
    "            # Raise error if path is invalid\n",
    "            raise ValueError('Invalid `path` variable. Needs to be a directory.')\n",
    "        \n",
    "        self.scripts = []\n",
    "        \n",
    "        # Get all files from path\n",
    "        files_names = os.listdir(path)\n",
    "        # Go through each file and read its content\n",
    "        for file_name in tqdm(files_names, desc=f'script files'):\n",
    "            file_path = os.path.join(path, file_name)\n",
    "            \n",
    "            # Read content\n",
    "            content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "            # Fix any unicode issues\n",
    "            content = fix_content(content)\n",
    "            # Save content\n",
    "            self.scripts.append(content)\n",
    "        \n",
    "        # Number of examples\n",
    "        self.n_sexamples = len(self.examples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        r'''When used `len` return the number of examples.\n",
    "        '''\n",
    "        \n",
    "        return self.n_examples\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        r'''Given an index return an example from the position.\n",
    "        \n",
    "        Arguments:\n",
    "            item(:obj:`int`):\n",
    "                Index position to pick an example to return.\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`str`: Script of the index position.\n",
    "        '''\n",
    "        \n",
    "        return self.scripts[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bbc42-23c1-44b9-9a44-b1bf24ecd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2ScriptWritingCollator(object):\n",
    "    r'''Data Collator used for GPT-2 in a script writing task.\n",
    "    \n",
    "    It uses a given tokenizer and its encoder to convert any text to numbers that can go straight into a GPT-2 model.\n",
    "    \n",
    "    Arguments:\n",
    "        use_tokenizer(:obj:`transformers.tokenization_?`):\n",
    "            Transformer type tokenizer used to process raw text into numbers\n",
    "        max_sequence_len(:obj:`int`, `optional`):\n",
    "            Value to indicate the maximum desired sequence to truncate or pad text sequences.\n",
    "            If no value is passed it will used maximum sequence size supported by the tokenizer and model.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, use_tokenizer, max_sequence_len=None):\n",
    "        # Tokenizer to be used inside the class\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        # Check max sequence length\n",
    "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
    "    \n",
    "    def __call__(self, sequences):\n",
    "        r'''This function allowes the class object to be used as a function call.\n",
    "        Since the PyTorch DataLoader needs a collator function, can use this class as a function.\n",
    "        \n",
    "        Arguments:\n",
    "            item(:obj:`list`):\n",
    "                List of texts.\n",
    "        \n",
    "        Returns:\n",
    "            :obj:`Dict[str, object]`: Dictionary of inputs that feed into the model.\n",
    "            It holds the statement `model(**Returned Dictionary)`.\n",
    "        '''\n",
    "        \n",
    "        # Get all texts from sequences list\n",
    "        text = [sequence['text'] for sequence in sequences]\n",
    "        # Call tokenizer on all texts to convert into tensors of numbers with appropriate padding\n",
    "        inputs = self.use_tokenizer(text=text, return_tensors='pt', padding=True, truncate=True, max_length=self.max_sequence_len)\n",
    "        \n",
    "        return inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
