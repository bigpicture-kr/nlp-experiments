{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 Model Experiment 1<br>\n",
    "Topic classification of news articles written in Korean\n",
    "- Data: [국립국어원 신문 말뭉치(v2)](https://corpus.korean.go.kr/) sampling data\n",
    "- Model: [SKT AI KoGPT2](https://github.com/SKT-AI/KoGPT2) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Seongbum Seo](https://github.com/Seongbuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q git+https://github.com/huggingface/transformers.git\n",
    "#%pip install -q git+https://github.com/gmihaila/ml_things.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/SKT-AI/KoGPT2\n",
    "#%pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from ml_things import plot_dict, plot_confusion_matrix, fix_text\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import (set_seed, TrainingArguments, Trainer, GPT2Config, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup, GPT2ForSequenceClassification)\n",
    "\n",
    "set_seed(123)\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 32\n",
    "max_length = 60\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name_or_path = 'skt/kogpt2-base-v2'\n",
    "train_data_path = './data/sample_500_50/train'\n",
    "test_data_path = './data/sample_500_50/validation'\n",
    "\n",
    "labels_ids = {\n",
    "    'ITscience': 0,\n",
    "    'culture': 1,\n",
    "    'economy': 2,\n",
    "    'entertainment': 3,\n",
    "    'health': 4,\n",
    "    'life': 5,\n",
    "    'politic': 6,\n",
    "    'social': 7,\n",
    "    'sport': 8\n",
    "}\n",
    "label_names = list(labels_ids.keys())\n",
    "n_labels = len(labels_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, path, use_tokenizer):\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError('Invalid `path` variable. Needs to be a directory.')\n",
    "        \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label in label_names:\n",
    "            sentiment_path = os.path.join(path, label)\n",
    "\n",
    "            files_names = os.listdir(sentiment_path)#[:10] # Sample for debugging\n",
    "            for file_name in tqdm(files_names, desc=f'{label} files'):\n",
    "                file_path = os.path.join(sentiment_path, file_name)\n",
    "\n",
    "                content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "                content = fix_text(content)\n",
    "                self.texts.append(content)\n",
    "                self.labels.append(label)\n",
    "            \n",
    "        self.n_examples = len(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'text': self.texts[item],\n",
    "            'label': self.labels[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2ClassificationCollator(object):\n",
    "    def __init__(self, use_tokenizer, labels_encoder, max_sequence_len=None):\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
    "        self.labels_encoder = labels_encoder\n",
    "    \n",
    "    def __call__(self, sequences):\n",
    "        texts = [sequence['text'] for sequence in sequences]\n",
    "        labels = [sequence['label'] for sequence in sequences]\n",
    "        labels = [self.labels_encoder[label] for label in labels]\n",
    "        inputs = self.use_tokenizer(text=texts, return_tensors='pt', padding=True, truncation=True, max_length=self.max_sequence_len)\n",
    "        inputs.update({'labels': torch.tensor(labels)})\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer_, scheduler_, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        print(len(batch['input_ids']))\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer_.step()\n",
    "        scheduler_.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n",
    "\n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        while torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss, logits = outputs[:2]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predict_content = logits.argmax(axis=-1).flatten().tolist()\n",
    "            predictions_labels += predict_content\n",
    "    \n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading configuration...')\n",
    "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name_or_path, num_labels=n_labels)\n",
    "\n",
    "print('Loading tokenizer...')\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    bos_token='</s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>',\n",
    "    mask_token='<mask>'\n",
    ")\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print('Loading model...')\n",
    "model = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path, config=model_config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "print(f'Model loaded to `{device}`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset_size = int(len(dataset) * 0.6)\n",
    "#valid_dataset_size = int(len(dataset) * 0.2)\n",
    "#test_dataset_size = len(dataset) - train_dataset_size - valid_dataset_size\n",
    "#train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_dataset_size, valid_dataset_size, test_dataset_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_classification_collator = Gpt2ClassificationCollator(\n",
    "    use_tokenizer=tokenizer,\n",
    "    labels_encoder=labels_ids,\n",
    "    max_sequence_len=max_length\n",
    ")\n",
    "\n",
    "print('Dealing with train...')\n",
    "train_dataset = NewsDataset(path=train_data_path, use_tokenizer=tokenizer)\n",
    "print(f'Created `train_dataset` with {len(train_dataset)} examples.')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=gpt2_classification_collator)\n",
    "print(f'Created `train_dataloader` with {len(train_dataloader)} batches.')\n",
    "print()\n",
    "\n",
    "print('Dealing with validation...')\n",
    "valid_dataset = NewsDataset(path=test_data_path, use_tokenizer=tokenizer)\n",
    "print(f'Created `valid_dataset` with {len(valid_dataset)} examples.')\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classification_collator)\n",
    "print(f'Created `valid_dataloader` with {len(valid_dataloader)} batches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8) # by default lr is 5e-5 and eps is 1e-8\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "all_loss = {'train_loss': [], 'val_loss': []}\n",
    "all_acc = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print('Epoch')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print()\n",
    "    print('Training on batches...')\n",
    "    train_labels, train_predict, train_loss = train(train_dataloader, optimizer, scheduler, device)\n",
    "    train_acc = accuracy_score(train_labels, train_predict)\n",
    "\n",
    "    print('Validation on batches...')\n",
    "    valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\n",
    "    val_acc = accuracy_score(valid_labels, valid_predict)\n",
    "\n",
    "    print('  train_loss: %.5f - val_loss: %.5f - train_acc: %.5f - val_acc: %.5f' % (train_loss, val_loss, train_acc, val_acc))\n",
    "    print()\n",
    "\n",
    "    all_loss['train_loss'].append(train_loss)\n",
    "    all_loss['val_loss'].append(val_loss)\n",
    "    all_acc['train_acc'].append(train_acc)\n",
    "    all_acc['val_acc'].append(val_acc)\n",
    "\n",
    "plot_dict(all_loss, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'], use_title='Loss')\n",
    "plot_dict(all_acc, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'], use_title='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions_labels, avg_epoch_loss = validation(valid_dataloader, device)\n",
    "\n",
    "evaluation_report = classification_report(true_labels, predictions_labels, labels=list(labels_ids.values()), target_names=label_names)\n",
    "print(evaluation_report)\n",
    "\n",
    "plot_confusion_matrix(y_true=true_labels, y_pred=predictions_labels, classes=label_names, normalize=True, magnify=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5eb98d62cb1847a13fed7eb12c2a9611413ceb2c75685db78a43742deebc44b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
