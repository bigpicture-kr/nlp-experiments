{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 Model Experiment 1\n",
    "- Data: [국립국어원 신문 말뭉치(v2)](https://corpus.korean.go.kr/) sampling data\n",
    "- Model: [SKT AI KoGPT2](https://github.com/SKT-AI/KoGPT2) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Seongbum Seo](https://github.com/Seongbuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/huggingface/transformers.git\n",
    "%pip install -q git+https://github.com/gmihaila/ml_things.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'KoGPT2' already exists and is not an empty directory.\n",
      "Requirement already satisfied: matplotlib==3.1.3 in ./.venv/lib/python3.8/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.22.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.4.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SKT-AI/KoGPT2\n",
    "%pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ml_things import plot_dict, plot_confusion_matrix, fix_text\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import (set_seed, TrainingArguments, Trainer, GPT2Config, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup, GPT2ForTokenClassification)\n",
    "\n",
    "set_seed(123)\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 32\n",
    "max_length = 60\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name_or_path = 'skt/kogpt2-base-v2'\n",
    "\n",
    "labels_ids = {\n",
    "    'ITscience': 0,\n",
    "    'culture': 1,\n",
    "    'economy': 2,\n",
    "    'entertainment': 3,\n",
    "    'health': 4,\n",
    "    'life': 5,\n",
    "    'politic': 6,\n",
    "    'social': 7,\n",
    "    'sport': 8\n",
    "}\n",
    "label_names = labels_ids.keys()\n",
    "n_labels = len(labels_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, path, use_tokenizer):\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError('Invalid `path` variable. Needs to be a directory.')\n",
    "        \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label in label_names:\n",
    "            sentiment_path = os.path.join(path, label)\n",
    "\n",
    "            files_names = os.listdir(sentiment_path)#[:10] # Sample for debugging\n",
    "            for file_name in tqdm(files_names, desc=f'{label} files'):\n",
    "                file_path = os.path.join(sentiment_path, file_name)\n",
    "\n",
    "                content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "                content = fix_text(content)\n",
    "                self.texts.append(content)\n",
    "                self.labels.append(label)\n",
    "            \n",
    "        self.n_examples = len(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'text': self.texts[item],\n",
    "            'label': self.labels[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2ClassificationCollator(object):\n",
    "    def __init__(self, use_tokenizer, labels_encoder, max_sequence_len=None):\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
    "        self.labels.encoder = labels_encoder\n",
    "    \n",
    "    def __call__(self, sequences):\n",
    "        texts = [sequence['text'] for sequence in sequences]\n",
    "        labels = [sequence['label'] for sequence in sequences]\n",
    "        labels = [self.labels_encoder[label] for label in labels]\n",
    "        inputs = self.use_tokenizer(text=texts, return_tensors='pt', padding=True, truncation=True, max_length=self.max_sequence_len)\n",
    "        inputs.update({'labels': torch.tensor(labels)})\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer_, scheduler_, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer_.step()\n",
    "        scheduler_.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n",
    "\n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        while torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss, logits = outputs[:2]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predict_content = logits.argmax(axis=-1).flatten().tolist()\n",
    "            predictions_labels += predict_content\n",
    "    \n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eb98d62cb1847a13fed7eb12c2a9611413ceb2c75685db78a43742deebc44b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
