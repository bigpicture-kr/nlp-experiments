{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 Model Experiment 1\n",
    "- Data: [국립국어원 신문 말뭉치(v2)](https://corpus.korean.go.kr/) sampling data\n",
    "- Model: [SKT AI KoGPT2](https://github.com/SKT-AI/KoGPT2) fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Seongbum Seo](https://github.com/Seongbuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbumseo/git/topic-classification/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/huggingface/transformers.git\n",
    "%pip install -q git+https://github.com/gmihaila/ml_things.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'KoGPT2' already exists and is not an empty directory.\n",
      "Collecting matplotlib==3.1.3\n",
      "  Using cached matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: numpy>=1.11 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.4.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib==3.1.3) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.16.0)\n",
      "\u001b[31mERROR: ml-things 0.0.1 has requirement matplotlib>=3.4.0, but you'll have matplotlib 3.1.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.2\n",
      "    Uninstalling matplotlib-3.5.2:\n",
      "      Successfully uninstalled matplotlib-3.5.2\n",
      "Successfully installed matplotlib-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SKT-AI/KoGPT2\n",
    "%pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ml_things import plot_dict, plot_confusion_matrix, fix_text\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import (set_seed, TrainingArguments, Trainer, GPT2Config, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup, GPT2ForTokenClassification)\n",
    "\n",
    "set_seed(123)\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 32\n",
    "max_length = 60\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name_or_path = 'skt/kogpt2-base-v2'\n",
    "train_data_path = 'sampling_train_data'\n",
    "test_data_path = 'sampling_test_data'\n",
    "\n",
    "labels_ids = {\n",
    "    'ITscience': 0,\n",
    "    'culture': 1,\n",
    "    'economy': 2,\n",
    "    'entertainment': 3,\n",
    "    'health': 4,\n",
    "    'life': 5,\n",
    "    'politic': 6,\n",
    "    'social': 7,\n",
    "    'sport': 8\n",
    "}\n",
    "label_names = list(labels_ids.keys())\n",
    "n_labels = len(labels_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, path, use_tokenizer):\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError('Invalid `path` variable. Needs to be a directory.')\n",
    "        \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label in label_names:\n",
    "            sentiment_path = os.path.join(path, label)\n",
    "\n",
    "            files_names = os.listdir(sentiment_path)#[:10] # Sample for debugging\n",
    "            for file_name in tqdm(files_names, desc=f'{label} files'):\n",
    "                file_path = os.path.join(sentiment_path, file_name)\n",
    "\n",
    "                content = io.open(file_path, mode='r', encoding='utf-8').read()\n",
    "                content = fix_text(content)\n",
    "                self.texts.append(content)\n",
    "                self.labels.append(label)\n",
    "            \n",
    "        self.n_examples = len(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'text': self.texts[item],\n",
    "            'label': self.labels[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2ClassificationCollator(object):\n",
    "    def __init__(self, use_tokenizer, labels_encoder, max_sequence_len=None):\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
    "        self.labels.encoder = labels_encoder\n",
    "    \n",
    "    def __call__(self, sequences):\n",
    "        texts = [sequence['text'] for sequence in sequences]\n",
    "        labels = [sequence['label'] for sequence in sequences]\n",
    "        labels = [self.labels_encoder[label] for label in labels]\n",
    "        inputs = self.use_tokenizer(text=texts, return_tensors='pt', padding=True, truncation=True, max_length=self.max_sequence_len)\n",
    "        inputs.update({'labels': torch.tensor(labels)})\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer_, scheduler_, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer_.step()\n",
    "        scheduler_.step()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n",
    "\n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, device_):\n",
    "    # Use global variable for model\n",
    "    global model\n",
    "\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        true_labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {k: v.type(torch.long).to(device_) for k, v in batch.items()}\n",
    "\n",
    "        while torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            loss, logits = outputs[:2]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predict_content = logits.argmax(axis=-1).flatten().tolist()\n",
    "            predictions_labels += predict_content\n",
    "    \n",
    "    avg_epoch_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2ForTokenClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to `cuda`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbumseo/git/topic-classification/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA GeForce RTX 3060 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "print('Loading configuration...')\n",
    "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_name_or_path, num_labels=n_labels)\n",
    "\n",
    "print('Loading tokenizer...')\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name_or_path,\n",
    "    bos_token='</s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>',\n",
    "    mask_token='<mask>'\n",
    ")\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print('Loading model...')\n",
    "model = GPT2ForTokenClassification.from_pretrained(pretrained_model_name_or_path=model_name_or_path, config=model_config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(device)\n",
    "print(f'Model loaded to `{device}`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Gpt2ClassificationCollator' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m gpt2_classification_collator \u001b[39m=\u001b[39m Gpt2ClassificationCollator(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m     use_tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m     labels_encoder\u001b[39m=\u001b[39;49mlabels_ids,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=3'>4</a>\u001b[0m     max_sequence_len\u001b[39m=\u001b[39;49mmax_length\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDealing with train...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000016vscode-remote?line=7'>8</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m NewsDataset(path\u001b[39m=\u001b[39mtrain_data_path, use_tokenizer\u001b[39m=\u001b[39mtokenizer)\n",
      "\u001b[1;32m/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb Cell 12'\u001b[0m in \u001b[0;36mGpt2ClassificationCollator.__init__\u001b[0;34m(self, use_tokenizer, labels_encoder, max_sequence_len)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_tokenizer \u001b[39m=\u001b[39m use_tokenizer\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sequence_len \u001b[39m=\u001b[39m use_tokenizer\u001b[39m.\u001b[39mmodel_max_length \u001b[39mif\u001b[39;00m max_sequence_len \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m max_sequence_len\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbigpicture/home/sbumseo/git/topic-classification/NewsTopicClassification.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m labels_encoder\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Gpt2ClassificationCollator' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "gpt2_classification_collator = Gpt2ClassificationCollator(\n",
    "    use_tokenizer=tokenizer,\n",
    "    labels_encoder=labels_ids,\n",
    "    max_sequence_len=max_length\n",
    ")\n",
    "\n",
    "print('Dealing with train...')\n",
    "train_dataset = NewsDataset(path=train_data_path, use_tokenizer=tokenizer)\n",
    "print(f'Created `train_dataset` with {len(train_dataset)} examples.')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=gpt2_classification_collator)\n",
    "print(f'Created `train_dataloader` with {len(train_dataloader)} batches.')\n",
    "print()\n",
    "\n",
    "print('Dealing with validation...')\n",
    "valid_dataset = NewsDataset(path=test_data_path, use_tokenizer=tokenizer)\n",
    "print(f'Created `valid_dataset` with {len(valid_dataset)} examples.')\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classification_collator)\n",
    "print(f'Created `valid_dataloader` with {len(valid_dataloader)} batches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8) # by default lr is 5e-5 and eps is 1e-8\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "all_loss = {'train_loss': [], 'val_loss': []}\n",
    "all_acc = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print('Epoch')\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print()\n",
    "    print('Training on batches...')\n",
    "    train_labels, train_predict, train_loss = train(train_dataloader, optimizer, scheduler, device)\n",
    "    train_acc = accuracy_score(train_labels, train_predict)\n",
    "\n",
    "    print('Validation on batches...')\n",
    "    valid_labels, valid_predict, val_loss = validation(valid_dataloader, device)\n",
    "    val_acc = accuracy_score(valid_labels, valid_predict)\n",
    "\n",
    "    print('  train_loss: %.5f - val_loss: %.5f - train_acc: %.5f - val_acc: %.5f' % (train_loss, val_loss, train_acc, val_acc))\n",
    "    print()\n",
    "\n",
    "    all_loss['train_loss'].append(train_loss)\n",
    "    all_loss['val_loss'].append(val_loss)\n",
    "    all_acc['train_acc'].append(train_acc)\n",
    "    all_acc['val_acc'].append(val_acc)\n",
    "\n",
    "plot_dict(all_loss, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'], use_title='Loss')\n",
    "plot_dict(all_acc, use_xlabel='Epochs', use_ylabel='Value', use_linestyles=['-', '--'], use_title='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions_labels, avg_epoch_loss = validation(valid_dataloader, device)\n",
    "\n",
    "evaluation_report = classification_report(true_labels, predictions_labels, labels=list(labels_ids.values()), target_names=label_names)\n",
    "print(evaluation_report)\n",
    "\n",
    "plot_confusion_matrix(y_true=true_labels, y_pred=predictions_labels, classes=label_names, normalize=True, magnify=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eb98d62cb1847a13fed7eb12c2a9611413ceb2c75685db78a43742deebc44b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
